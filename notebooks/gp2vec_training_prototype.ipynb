{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68b8fbd7",
   "metadata": {},
   "source": [
    "# GP2Vec Training Prototype\n",
    "\n",
    "This notebook demonstrates the complete GP2Vec training pipeline using small synthetic datasets for rapid prototyping and testing. We'll walk through:\n",
    "\n",
    "1. **Data Generation**: Create synthetic seismic-like waveforms\n",
    "2. **Model Architecture**: Build a simplified GP2Vec model\n",
    "3. **Training Pipeline**: Train with PyTorch Lightning\n",
    "4. **Evaluation**: Test the learned representations\n",
    "5. **Visualization**: Monitor training progress and results\n",
    "\n",
    "This prototype uses small batches and limited data to enable fast iteration and debugging of the self-supervised learning approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa467db8",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "First, let's import all the necessary libraries for our GP2Vec prototype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de104e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from scipy.stats import norm\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime, timezone\n",
    "from datetimerange import DateTimeRange\n",
    "\n",
    "# PyTorch and Lightning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, RichProgressBar\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "# ObsPy for seismic data\n",
    "import obspy\n",
    "from obspy import UTCDateTime, Stream, Trace\n",
    "from obspy.clients.fdsn import Client\n",
    "\n",
    "# S3 and cloud data access\n",
    "import s3fs\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "\n",
    "# GP2Vec modules (we'll create simplified versions)\n",
    "try:\n",
    "    from src.gp2vec.models.gp2vec import GP2Vec\n",
    "    from src.gp2vec.models.feature_encoder import FeatureEncoder\n",
    "    from src.gp2vec.models.vq import GumbelVectorQuantizer\n",
    "    from src.gp2vec.models.transformer import TransformerContextEncoder\n",
    "    from src.gp2vec.models.losses import GP2VecLoss\n",
    "    print(\"âœ“ Successfully imported GP2Vec modules\")\n",
    "except ImportError as e:\n",
    "    print(f\"âš  Could not import GP2Vec modules: {e}\")\n",
    "    print(\"We'll define simplified versions in this notebook\")\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "pl.seed_everything(42)\n",
    "\n",
    "print(\"ðŸ“¦ All libraries imported successfully!\")\n",
    "print(f\"ðŸ”§ PyTorch version: {torch.__version__}\")\n",
    "print(f\"âš¡ Lightning version: {pl.__version__}\")\n",
    "print(f\"\udcca ObsPy version: {obspy.__version__}\")\n",
    "print(f\"\ud83dðŸ–¥ï¸  Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "# Test S3 connectivity\n",
    "try:\n",
    "    # Test anonymous access to SCEDC bucket\n",
    "    s3 = s3fs.S3FileSystem(anon=True)\n",
    "    bucket_contents = s3.ls('scedc-pds/continuous_waveforms/', max_items=5)\n",
    "    print(f\"âœ… S3 connection successful! Found {len(bucket_contents)} directories in SCEDC bucket\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ S3 connection issue: {e}\")\n",
    "    print(\"Will fall back to synthetic data if needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a295ac1e",
   "metadata": {},
   "source": [
    "## 2. Access Real Seismic Data from SCEDC S3\n",
    "\n",
    "Instead of synthetic data, we'll now access real continuous seismic data from the SCEDC (Southern California Earthquake Data Center) S3 bucket. This includes:\n",
    "- **Continuous waveforms**: Real 3-component seismic data from Southern California\n",
    "- **Multiple networks**: CI, AZ, US networks available\n",
    "- **Station metadata**: FDSN stationXML with instrument responses\n",
    "- **Time series data**: miniSEED format organized by day/station/channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410eac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCEDCSeismicDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch dataset for loading real seismic data from SCEDC S3 bucket.\n",
    "    \n",
    "    The SCEDC provides continuous seismic waveforms organized as:\n",
    "    s3://scedc-pds/continuous_waveforms/{year}/{year}_{julian_day:03d}/{network}_{station}_{location}_{channel}_{year}_{julian_day:03d}.ms\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        start_date=\"2023-01-01\",\n",
    "        num_days=3,  # Small number for prototyping\n",
    "        networks=[\"CI\"],  # Start with CI network\n",
    "        stations=[\"ADE\", \"ADO\", \"BAR\"],  # Select a few stations\n",
    "        channels=[\"BHE\", \"BHN\", \"BHZ\"],  # 3-component broadband\n",
    "        sample_length_sec=30.0,  # 30-second windows\n",
    "        sample_rate=100.0,  # Target sample rate\n",
    "        samples_per_day=10,  # Small number for prototyping\n",
    "        transform=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        self.num_days = num_days\n",
    "        self.networks = networks\n",
    "        self.stations = stations\n",
    "        self.channels = channels\n",
    "        self.sample_length_sec = sample_length_sec\n",
    "        self.sample_rate = sample_rate\n",
    "        self.samples_per_day = samples_per_day\n",
    "        self.transform = transform\n",
    "        self.sample_length_pts = int(sample_length_sec * sample_rate)\n",
    "        \n",
    "        # Initialize S3 filesystem (anonymous access)\n",
    "        self.fs = s3fs.S3FileSystem(anon=True)\n",
    "        self.bucket = \"scedc-pds\"\n",
    "        self.base_path = \"continuous_waveforms\"\n",
    "        \n",
    "        # Build list of available data files\n",
    "        self._build_file_list()\n",
    "        \n",
    "        # Station metadata cache\n",
    "        self.station_metadata = {}\n",
    "        \n",
    "    def _build_file_list(self):\n",
    "        \"\"\"Build list of available miniSEED files for the specified parameters.\"\"\"\n",
    "        self.file_list = []\n",
    "        \n",
    "        for day_offset in range(self.num_days):\n",
    "            current_date = self.start_date + timedelta(days=day_offset)\n",
    "            year = current_date.year\n",
    "            julian_day = current_date.timetuple().tm_yday\n",
    "            \n",
    "            for network in self.networks:\n",
    "                for station in self.stations:\n",
    "                    # Look for files for this station/day\n",
    "                    day_path = f\"{self.base_path}/{year}/{year}_{julian_day:03d}\"\n",
    "                    \n",
    "                    try:\n",
    "                        # List files for this day\n",
    "                        full_path = f\"{self.bucket}/{day_path}\"\n",
    "                        files = self.fs.glob(f\"{full_path}/{network}_{station}_*_*.ms\")\n",
    "                        \n",
    "                        # Group by location and check for 3-component data\n",
    "                        station_files = {}\n",
    "                        for file_path in files:\n",
    "                            filename = file_path.split('/')[-1]\n",
    "                            parts = filename.replace('.ms', '').split('_')\n",
    "                            if len(parts) >= 4:\n",
    "                                net, sta, loc, cha = parts[:4]\n",
    "                                if sta == station and net == network:\n",
    "                                    key = f\"{net}_{sta}_{loc}\"\n",
    "                                    if key not in station_files:\n",
    "                                        station_files[key] = {}\n",
    "                                    station_files[key][cha] = f\"s3://{file_path}\"\n",
    "                        \n",
    "                        # Add complete 3-component sets\n",
    "                        for station_key, channels_dict in station_files.items():\n",
    "                            available_channels = set(channels_dict.keys())\n",
    "                            target_channels = set(self.channels)\n",
    "                            \n",
    "                            # Check if we have at least 2 components (can work with incomplete sets)\n",
    "                            if len(available_channels.intersection(target_channels)) >= 2:\n",
    "                                self.file_list.append({\n",
    "                                    'date': current_date,\n",
    "                                    'station_key': station_key,\n",
    "                                    'files': channels_dict,\n",
    "                                    'network': network,\n",
    "                                    'station': station\n",
    "                                })\n",
    "                                \n",
    "                    except Exception as e:\n",
    "                        print(f\"Warning: Could not access {day_path}: {e}\")\n",
    "                        continue\n",
    "        \n",
    "        print(f\"Found {len(self.file_list)} station-days with multi-component data\")\n",
    "        \n",
    "    def _get_station_metadata(self, network, station):\n",
    "        \"\"\"Get station metadata from SCEDC FDSN.\"\"\"\n",
    "        key = f\"{network}.{station}\"\n",
    "        \n",
    "        if key not in self.station_metadata:\n",
    "            try:\n",
    "                # Use ObsPy to get station metadata\n",
    "                from obspy.clients.fdsn import Client\n",
    "                client = Client(\"SCEDC\")\n",
    "                \n",
    "                # Get station info (try recent date)\n",
    "                inventory = client.get_stations(\n",
    "                    network=network, station=station,\n",
    "                    starttime=UTCDateTime(\"2023-01-01\"),\n",
    "                    level=\"station\"\n",
    "                )\n",
    "                \n",
    "                if inventory:\n",
    "                    net = inventory[0]\n",
    "                    sta = net[0]\n",
    "                    self.station_metadata[key] = {\n",
    "                        'latitude': sta.latitude,\n",
    "                        'longitude': sta.longitude,\n",
    "                        'elevation': sta.elevation,\n",
    "                        'creation_date': sta.creation_date,\n",
    "                        'site_name': sta.site.name if sta.site else \"Unknown\"\n",
    "                    }\n",
    "                else:\n",
    "                    # Fallback metadata\n",
    "                    self.station_metadata[key] = {\n",
    "                        'latitude': 34.0,  # Rough SoCal center\n",
    "                        'longitude': -118.0,\n",
    "                        'elevation': 100.0,\n",
    "                        'creation_date': UTCDateTime(\"2000-01-01\"),\n",
    "                        'site_name': \"Unknown\"\n",
    "                    }\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not get metadata for {key}: {e}\")\n",
    "                # Fallback metadata\n",
    "                self.station_metadata[key] = {\n",
    "                    'latitude': 34.0 + np.random.uniform(-2, 2),\n",
    "                    'longitude': -118.0 + np.random.uniform(-2, 2),\n",
    "                    'elevation': 100.0 + np.random.uniform(-50, 500),\n",
    "                    'creation_date': UTCDateTime(\"2000-01-01\"),\n",
    "                    'site_name': \"Unknown\"\n",
    "                }\n",
    "        \n",
    "        return self.station_metadata[key]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_list) * self.samples_per_day\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Determine which station-day and which sample within that day\n",
    "        file_idx = idx // self.samples_per_day\n",
    "        sample_idx = idx % self.samples_per_day\n",
    "        \n",
    "        if file_idx >= len(self.file_list):\n",
    "            raise IndexError(f\"Index {idx} out of range\")\n",
    "            \n",
    "        file_info = self.file_list[file_idx]\n",
    "        \n",
    "        try:\n",
    "            # Load waveform data\n",
    "            waveforms = []\n",
    "            channel_names = []\n",
    "            \n",
    "            for channel in self.channels:\n",
    "                if channel in file_info['files']:\n",
    "                    file_path = file_info['files'][channel]\n",
    "                    \n",
    "                    # Read miniSEED file from S3\n",
    "                    with self.fs.open(file_path, 'rb') as f:\n",
    "                        st = read(f, format='MSEED')\n",
    "                    \n",
    "                    if st and len(st) > 0:\n",
    "                        tr = st[0]  # Take first trace\n",
    "                        \n",
    "                        # Basic preprocessing\n",
    "                        tr.detrend('linear')\n",
    "                        tr.filter('bandpass', freqmin=1.0, freqmax=45.0)\n",
    "                        \n",
    "                        # Resample if needed\n",
    "                        if abs(tr.stats.sampling_rate - self.sample_rate) > 0.1:\n",
    "                            tr.resample(self.sample_rate)\n",
    "                        \n",
    "                        waveforms.append(tr.data)\n",
    "                        channel_names.append(channel)\n",
    "                \n",
    "            if len(waveforms) == 0:\n",
    "                raise ValueError(\"No valid waveforms found\")\n",
    "            \n",
    "            # Ensure all traces have the same length\n",
    "            min_length = min(len(w) for w in waveforms)\n",
    "            if min_length < self.sample_length_pts:\n",
    "                # Pad with zeros if too short\n",
    "                for i in range(len(waveforms)):\n",
    "                    if len(waveforms[i]) < self.sample_length_pts:\n",
    "                        waveforms[i] = np.pad(waveforms[i], \n",
    "                                            (0, self.sample_length_pts - len(waveforms[i])), \n",
    "                                            'constant')\n",
    "                min_length = self.sample_length_pts\n",
    "            \n",
    "            # Extract random window\n",
    "            if min_length > self.sample_length_pts:\n",
    "                max_start = min_length - self.sample_length_pts\n",
    "                start_idx = np.random.randint(0, max_start + 1)\n",
    "                waveforms = [w[start_idx:start_idx + self.sample_length_pts] for w in waveforms]\n",
    "            \n",
    "            # Stack to create 3-component array (pad with zeros if needed)\n",
    "            while len(waveforms) < 3:\n",
    "                waveforms.append(np.zeros(self.sample_length_pts))\n",
    "                channel_names.append(\"PAD\")\n",
    "            \n",
    "            # Take only first 3 components\n",
    "            waveforms = waveforms[:3]\n",
    "            channel_names = channel_names[:3]\n",
    "            \n",
    "            data = np.stack(waveforms, axis=0).astype(np.float32)\n",
    "            \n",
    "            # Normalize each component\n",
    "            for i in range(data.shape[0]):\n",
    "                std = np.std(data[i])\n",
    "                if std > 0:\n",
    "                    data[i] = data[i] / std\n",
    "            \n",
    "            # Get station metadata\n",
    "            metadata = self._get_station_metadata(file_info['network'], file_info['station'])\n",
    "            \n",
    "            # Create metadata tensor (normalized coordinates)\n",
    "            metadata_tensor = torch.tensor([\n",
    "                (metadata['latitude'] - 34.0) / 5.0,  # Normalize around SoCal\n",
    "                (metadata['longitude'] + 118.0) / 5.0,\n",
    "                metadata['elevation'] / 1000.0,  # Convert to km\n",
    "                float(metadata['creation_date'].timestamp) / 1e9  # Normalize timestamp\n",
    "            ], dtype=torch.float32)\n",
    "            \n",
    "            sample = {\n",
    "                'waveform': torch.from_numpy(data),\n",
    "                'metadata': metadata_tensor,\n",
    "                'station_id': f\"{file_info['network']}.{file_info['station']}\",\n",
    "                'date': file_info['date'].strftime(\"%Y-%m-%d\"),\n",
    "                'channels': channel_names\n",
    "            }\n",
    "            \n",
    "            if self.transform:\n",
    "                sample = self.transform(sample)\n",
    "                \n",
    "            return sample\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data for index {idx}: {e}\")\n",
    "            # Return dummy data in case of error\n",
    "            dummy_data = np.random.randn(3, self.sample_length_pts).astype(np.float32)\n",
    "            dummy_metadata = torch.zeros(4, dtype=torch.float32)\n",
    "            \n",
    "            return {\n",
    "                'waveform': torch.from_numpy(dummy_data),\n",
    "                'metadata': dummy_metadata,\n",
    "                'station_id': \"DUMMY.DUMMY\",\n",
    "                'date': \"2023-01-01\",\n",
    "                'channels': [\"ERR\", \"ERR\", \"ERR\"]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086dbbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the SCEDC dataset with real S3 data\n",
    "print(\"Creating SCEDC dataset with real S3 data...\")\n",
    "real_dataset = SCEDCSeismicDataset(\n",
    "    start_date=\"2023-01-01\",\n",
    "    num_days=2,  # Just 2 days for quick prototyping\n",
    "    samples_per_day=5,  # 5 samples per station-day\n",
    "    networks=[\"CI\"],\n",
    "    stations=[\"ADE\", \"ADO\", \"BAR\", \"BBS\", \"CCC\"]  # Some common CI stations\n",
    ")\n",
    "\n",
    "print(f\"Dataset size: {len(real_dataset)} samples\")\n",
    "\n",
    "if len(real_dataset) > 0:\n",
    "    # Test loading a sample\n",
    "    print(\"Testing sample loading...\")\n",
    "    sample = real_dataset[0]\n",
    "    print(f\"Sample keys: {sample.keys()}\")\n",
    "    print(f\"Waveform shape: {sample['waveform'].shape}\")\n",
    "    print(f\"Station ID: {sample['station_id']}\")\n",
    "    print(f\"Date: {sample['date']}\")\n",
    "    print(f\"Channels: {sample['channels']}\")\n",
    "    print(f\"Metadata shape: {sample['metadata'].shape}\")\n",
    "    print(\"âœ“ Successfully loaded real SCEDC data!\")\n",
    "else:\n",
    "    print(\"âš ï¸ No data found - check date range and station availability\")\n",
    "    # Fallback to synthetic data for the prototype\n",
    "    print(\"Falling back to synthetic data for the prototype...\")\n",
    "    real_dataset = SyntheticSeismicDataset(\n",
    "        num_samples=50,\n",
    "        num_stations=5,\n",
    "        sample_length_sec=30.0,\n",
    "        sample_rate=100.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd6a85e",
   "metadata": {},
   "source": [
    "## 2.5. Load Pre-trained Wav2Vec2 Weights\n",
    "\n",
    "Now we'll extract and load pre-trained Wav2Vec2 weights to initialize our GP2Vec model. This transfer learning approach leverages the powerful representations learned by Wav2Vec2 on speech data and adapts them for seismic signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a2fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and load pre-trained Wav2Vec2 weights\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# First, let's extract the weights if they don't exist\n",
    "weights_dir = Path(\"../weights\")\n",
    "weights_dir.mkdir(exist_ok=True)\n",
    "weights_path = weights_dir / \"wav2vec2_base_weights.pth\"\n",
    "\n",
    "if not weights_path.exists():\n",
    "    print(\"ðŸ”§ Extracting Wav2Vec2 weights for the first time...\")\n",
    "    print(\"This will download the pre-trained model and extract adapted weights.\")\n",
    "    \n",
    "    try:\n",
    "        # Import the weight extraction utility\n",
    "        from src.gp2vec.utils.wav2vec_transfer import Wav2Vec2WeightExtractor\n",
    "        \n",
    "        # Create extractor and save weights\n",
    "        extractor = Wav2Vec2WeightExtractor(\"facebook/wav2vec2-base-960h\")\n",
    "        extractor.save_weights(str(weights_path))\n",
    "        \n",
    "        print(f\"âœ… Weights extracted and saved to {weights_path}\")\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"âš ï¸ Could not import transformers library: {e}\")\n",
    "        print(\"Install with: pip install transformers\")\n",
    "        print(\"Proceeding without pre-trained weights...\")\n",
    "        weights_path = None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error extracting weights: {e}\")\n",
    "        print(\"Proceeding without pre-trained weights...\")\n",
    "        weights_path = None\n",
    "else:\n",
    "    print(f\"âœ… Found existing Wav2Vec2 weights at {weights_path}\")\n",
    "\n",
    "# Load the weights info if available\n",
    "if weights_path and weights_path.exists():\n",
    "    try:\n",
    "        import torch\n",
    "        weights_info = torch.load(weights_path, map_location='cpu')\n",
    "        \n",
    "        print(f\"\\nðŸ“‹ Wav2Vec2 Weight Information:\")\n",
    "        print(f\"   - Source model: {weights_info['config']['model_name']}\")\n",
    "        print(f\"   - Hidden size: {weights_info['config']['hidden_size']}\")\n",
    "        print(f\"   - Transformer layers: {weights_info['config']['num_layers']}\")\n",
    "        print(f\"   - Attention heads: {weights_info['config']['num_heads']}\")\n",
    "        print(f\"   - File size: {weights_path.stat().st_size / (1024*1024):.1f} MB\")\n",
    "        \n",
    "        for component in ['feature_encoder', 'transformer', 'quantizer']:\n",
    "            if component in weights_info and isinstance(weights_info[component], dict):\n",
    "                print(f\"   - {component.replace('_', ' ').title()}: {len(weights_info[component])} parameters\")\n",
    "                \n",
    "        wav2vec_available = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error loading weight info: {e}\")\n",
    "        wav2vec_available = False\n",
    "else:\n",
    "    wav2vec_available = False\n",
    "    print(\"âš ï¸ Wav2Vec2 weights not available - will use random initialization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fd14b4",
   "metadata": {},
   "source": [
    "### Visualize Sample Waveforms\n",
    "\n",
    "Let's look at a few examples from our synthetic dataset to verify they look realistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37a2bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some sample waveforms\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Create time axis\n",
    "time_axis = np.arange(dataset.seq_length) / dataset.sampling_rate\n",
    "\n",
    "for i in range(4):\n",
    "    sample = dataset[i * 50]  # Sample every 50th waveform\n",
    "    waveform = sample['waveform'].numpy()\n",
    "    labels = sample['labels']\n",
    "    metadata = sample['metadata']\n",
    "    \n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot 3 components\n",
    "    components = ['Z (Vertical)', 'N (North)', 'E (East)']\n",
    "    colors = ['blue', 'red', 'green']\n",
    "    \n",
    "    for comp in range(3):\n",
    "        ax.plot(time_axis, waveform[comp], \n",
    "               color=colors[comp], alpha=0.8, \n",
    "               label=components[comp], linewidth=0.8)\n",
    "    \n",
    "    # Mark P and S arrivals if present\n",
    "    if labels['has_event']:\n",
    "        ax.axvline(labels['p_arrival'], color='purple', \n",
    "                  linestyle='--', alpha=0.7, label='P arrival')\n",
    "        ax.axvline(labels['s_arrival'], color='orange', \n",
    "                  linestyle='--', alpha=0.7, label='S arrival')\n",
    "    \n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    ax.set_title(f'Sample {i}: {\"Event\" if labels[\"has_event\"] else \"Noise\"}\\n'\n",
    "                f'Lat: {metadata[\"latitude\"]:.2f}Â°, Lon: {metadata[\"longitude\"]:.2f}Â°')\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print dataset statistics\n",
    "event_count = sum(1 for i in range(len(dataset)) if dataset[i]['labels']['has_event'])\n",
    "print(f\"ðŸ“ˆ Dataset Statistics:\")\n",
    "print(f\"   - Total samples: {len(dataset)}\")\n",
    "print(f\"   - Event samples: {event_count} ({100*event_count/len(dataset):.1f}%)\")\n",
    "print(f\"   - Noise samples: {len(dataset)-event_count} ({100*(len(dataset)-event_count)/len(dataset):.1f}%)\")\n",
    "\n",
    "# Show metadata distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Latitude distribution\n",
    "axes[0].hist(dataset.metadata['latitude'].numpy(), bins=20, alpha=0.7, color='skyblue')\n",
    "axes[0].set_xlabel('Latitude (Â°)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Station Latitude Distribution')\n",
    "\n",
    "# Longitude distribution  \n",
    "axes[1].hist(dataset.metadata['longitude'].numpy(), bins=20, alpha=0.7, color='lightcoral')\n",
    "axes[1].set_xlabel('Longitude (Â°)')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Station Longitude Distribution')\n",
    "\n",
    "# Elevation distribution\n",
    "axes[2].hist(dataset.metadata['elevation'].numpy(), bins=20, alpha=0.7, color='lightgreen')\n",
    "axes[2].set_xlabel('Elevation (m)')\n",
    "axes[2].set_ylabel('Count')\n",
    "axes[2].set_title('Station Elevation Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f367c4",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Splitting\n",
    "\n",
    "Now we'll prepare the data for training by:\n",
    "1. Creating train/validation splits\n",
    "2. Setting up data loaders with small batch sizes\n",
    "3. Implementing data preprocessing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a6df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function for seismic data batches.\n",
    "    \"\"\"\n",
    "    # Stack waveforms\n",
    "    waveforms = torch.stack([item['waveform'] for item in batch])\n",
    "    \n",
    "    # Collect metadata\n",
    "    metadata = {}\n",
    "    for key in ['latitude', 'longitude', 'elevation']:\n",
    "        metadata[key] = torch.stack([item['metadata'][key] for item in batch])\n",
    "    \n",
    "    # Collect instruments (categorical)\n",
    "    instruments = [item['metadata']['instrument'] for item in batch]\n",
    "    \n",
    "    # Collect labels\n",
    "    labels = {}\n",
    "    for key in batch[0]['labels'].keys():\n",
    "        if key == 'has_event':\n",
    "            labels[key] = torch.tensor([item['labels'][key] for item in batch])\n",
    "        else:\n",
    "            # Only collect numeric labels for samples that have events\n",
    "            values = []\n",
    "            for item in batch:\n",
    "                if item['labels']['has_event'] and key in item['labels']:\n",
    "                    values.append(item['labels'][key])\n",
    "                else:\n",
    "                    values.append(0.0)  # Default value for non-events\n",
    "            labels[key] = torch.tensor(values)\n",
    "    \n",
    "    # Collect indices\n",
    "    indices = torch.tensor([item['idx'] for item in batch])\n",
    "    \n",
    "    return {\n",
    "        'waveform': waveforms,\n",
    "        'metadata': metadata,\n",
    "        'instruments': instruments,\n",
    "        'labels': labels,\n",
    "        'indices': indices\n",
    "    }\n",
    "\n",
    "# Split dataset into train/validation\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Use random split for simplicity (in practice, might use temporal or spatial splits)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size], \n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“Š Data split:\")\n",
    "print(f\"   - Training samples: {len(train_dataset)}\")\n",
    "print(f\"   - Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# Create data loaders with small batch sizes for prototyping\n",
    "batch_size = 8  # Small batch for rapid iteration\n",
    "num_workers = 2  # Reduced for notebook\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    persistent_workers=True if num_workers > 0 else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    persistent_workers=True if num_workers > 0 else False\n",
    ")\n",
    "\n",
    "print(f\"ðŸ”„ Data loaders created:\")\n",
    "print(f\"   - Batch size: {batch_size}\")\n",
    "print(f\"   - Train batches: {len(train_loader)}\")\n",
    "print(f\"   - Val batches: {len(val_loader)}\")\n",
    "\n",
    "# Test the data loader\n",
    "print(\"\\nðŸ§ª Testing data loader...\")\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(f\"   - Waveform batch shape: {sample_batch['waveform'].shape}\")\n",
    "print(f\"   - Metadata keys: {list(sample_batch['metadata'].keys())}\")\n",
    "print(f\"   - Labels keys: {list(sample_batch['labels'].keys())}\")\n",
    "print(f\"   - Has event distribution: {sample_batch['labels']['has_event'].sum().item()}/{len(sample_batch['labels']['has_event'])} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58397361",
   "metadata": {},
   "source": [
    "## 4. Define Simplified GP2Vec Architecture\n",
    "\n",
    "We'll create a simplified version of the GP2Vec model suitable for prototyping. This includes:\n",
    "- **Feature Encoder**: Simplified CNN\n",
    "- **Vector Quantizer**: Basic Gumbel-based quantization\n",
    "- **Context Encoder**: Small Transformer\n",
    "- **Contrastive Loss**: InfoNCE implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caec7c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GP2Vec model with optional Wav2Vec2 initialization\n",
    "print(\"ðŸ”§ Creating GP2Vec model...\")\n",
    "\n",
    "# Use production GP2Vec if available, otherwise use simplified version\n",
    "try:\n",
    "    from src.gp2vec.models.gp2vec import create_gp2vec_model\n",
    "    \n",
    "    # Create full GP2Vec model\n",
    "    model = create_gp2vec_model(\n",
    "        model_size=\"base\",  # Use base size for prototype\n",
    "        input_channels=3,\n",
    "        # metadata_config={\n",
    "        #     'categorical_features': {},\n",
    "        #     'continuous_features': ['latitude', 'longitude', 'elevation']\n",
    "        # }\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Created production GP2Vec model with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "    \n",
    "    # Load Wav2Vec2 weights if available\n",
    "    if wav2vec_available and weights_path and weights_path.exists():\n",
    "        print(\"ðŸ”„ Initializing with pre-trained Wav2Vec2 weights...\")\n",
    "        try:\n",
    "            stats = model.load_wav2vec_weights(weights_path, strict=False, verbose=True)\n",
    "            print(f\"âœ… Transferred {stats['updated_params']} parameters ({stats['update_ratio']:.1%} of model)\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Could not load Wav2Vec2 weights: {e}\")\n",
    "            print(\"Proceeding with random initialization...\")\n",
    "    else:\n",
    "        print(\"â„¹ï¸ Using random weight initialization\")\n",
    "        \n",
    "    using_production_model = True\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"âš ï¸ Production GP2Vec not available, using simplified version...\")\n",
    "    using_production_model = False\n",
    "    \n",
    "    # Fallback to simplified model (as defined earlier in notebook)\n",
    "    class SimpleFeatureEncoder(nn.Module):\n",
    "        \"\"\"Simplified CNN feature encoder for prototyping.\"\"\"\n",
    "        \n",
    "        def __init__(self, input_channels=3, embed_dim=256):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.layers = nn.ModuleList([\n",
    "                # Layer 1: (3, 3000) -> (64, 600)  \n",
    "                nn.Conv1d(input_channels, 64, kernel_size=10, stride=5),\n",
    "                nn.BatchNorm1d(64),\n",
    "                nn.GELU(),\n",
    "                \n",
    "                # Layer 2: (64, 600) -> (128, 150)\n",
    "                nn.Conv1d(64, 128, kernel_size=8, stride=4),\n",
    "                nn.BatchNorm1d(128), \n",
    "                nn.GELU(),\n",
    "                \n",
    "                # Layer 3: (128, 150) -> (256, 75)\n",
    "                nn.Conv1d(128, embed_dim, kernel_size=4, stride=2),\n",
    "                nn.BatchNorm1d(embed_dim),\n",
    "                nn.GELU(),\n",
    "            ])\n",
    "            \n",
    "            self.embed_dim = embed_dim\n",
    "            \n",
    "        def forward(self, x):\n",
    "            \"\"\"Forward pass through CNN layers.\"\"\"\n",
    "            # x: (batch, channels, time)\n",
    "            for i, layer in enumerate(self.layers):\n",
    "                x = layer(x)\n",
    "            \n",
    "            # Transpose to (batch, time, embed_dim)\n",
    "            return x.transpose(1, 2)\n",
    "\n",
    "    class SimpleVectorQuantizer(nn.Module):\n",
    "        \"\"\"Simplified Gumbel vector quantizer.\"\"\"\n",
    "        \n",
    "        def __init__(self, embed_dim=256, codebook_size=128, temperature=2.0):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.embed_dim = embed_dim\n",
    "            self.codebook_size = codebook_size\n",
    "            self.temperature = temperature\n",
    "            \n",
    "            # Learnable codebook\n",
    "            self.codebook = nn.Parameter(torch.randn(codebook_size, embed_dim))\n",
    "            \n",
    "            # Projection layer\n",
    "            self.project = nn.Linear(embed_dim, codebook_size)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            \"\"\"Quantize input features.\"\"\"\n",
    "            # x: (batch, time, embed_dim)\n",
    "            batch_size, seq_len, embed_dim = x.shape\n",
    "            \n",
    "            # Flatten for processing\n",
    "            x_flat = x.view(-1, embed_dim)  # (batch*time, embed_dim)\n",
    "            \n",
    "            # Compute logits\n",
    "            logits = self.project(x_flat)  # (batch*time, codebook_size)\n",
    "            \n",
    "            # Gumbel softmax\n",
    "            if self.training:\n",
    "                # Add Gumbel noise\n",
    "                gumbel_noise = -torch.log(-torch.log(torch.rand_like(logits) + 1e-8) + 1e-8)\n",
    "                soft_codes = F.softmax((logits + gumbel_noise) / self.temperature, dim=-1)\n",
    "            else:\n",
    "                soft_codes = F.softmax(logits / self.temperature, dim=-1)\n",
    "            \n",
    "            # Get quantized features\n",
    "            quantized = torch.matmul(soft_codes, self.codebook)  # (batch*time, embed_dim)\n",
    "            \n",
    "            # Reshape back\n",
    "            quantized = quantized.view(batch_size, seq_len, embed_dim)\n",
    "            \n",
    "            # Compute perplexity (measure of codebook usage)\n",
    "            avg_probs = soft_codes.mean(dim=0)\n",
    "            perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-8)))\n",
    "            \n",
    "            return quantized, 0.0, perplexity  # No VQ loss for Gumbel\n",
    "\n",
    "    class SimpleTransformer(nn.Module):\n",
    "        \"\"\"Simplified Transformer for context encoding.\"\"\"\n",
    "        \n",
    "        def __init__(self, embed_dim=256, num_heads=8, num_layers=4, dropout=0.1):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.embed_dim = embed_dim\n",
    "            \n",
    "            # Positional encoding\n",
    "            self.pos_encoding = nn.Parameter(torch.randn(1000, embed_dim) * 0.02)\n",
    "            \n",
    "            # Transformer layers\n",
    "            encoder_layer = nn.TransformerEncoderLayer(\n",
    "                d_model=embed_dim,\n",
    "                nhead=num_heads,\n",
    "                dim_feedforward=embed_dim * 4,\n",
    "                dropout=dropout,\n",
    "                activation='gelu',\n",
    "                batch_first=True\n",
    "            )\n",
    "            self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "            \n",
    "            # Layer norm\n",
    "            self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "            \n",
    "        def forward(self, x, mask=None):\n",
    "            \"\"\"Forward pass through transformer.\"\"\"\n",
    "            # x: (batch, time, embed_dim)\n",
    "            batch_size, seq_len, embed_dim = x.shape\n",
    "            \n",
    "            # Add positional encoding\n",
    "            pos_enc = self.pos_encoding[:seq_len].unsqueeze(0).expand(batch_size, -1, -1)\n",
    "            x = x + pos_enc\n",
    "            \n",
    "            # Apply transformer\n",
    "            x = self.transformer(x, src_key_padding_mask=mask)\n",
    "            \n",
    "            # Layer norm\n",
    "            x = self.layer_norm(x)\n",
    "            \n",
    "            return x\n",
    "\n",
    "    class SimpleMetadataEncoder(nn.Module):\n",
    "        \"\"\"Simple metadata encoder.\"\"\"\n",
    "        \n",
    "        def __init__(self, embed_dim=256):\n",
    "            super().__init__()\n",
    "            \n",
    "            # Coordinate embedding (lat, lon, elevation)\n",
    "            self.coord_proj = nn.Linear(3, embed_dim // 2)\n",
    "            \n",
    "            # Simple fusion\n",
    "            self.fusion = nn.Linear(embed_dim + embed_dim // 2, embed_dim)\n",
    "            self.dropout = nn.Dropout(0.1)\n",
    "            \n",
    "        def forward(self, features, metadata):\n",
    "            \"\"\"Fuse features with metadata.\"\"\"\n",
    "            # features: (batch, time, embed_dim)\n",
    "            # metadata: dict with lat, lon, elevation tensors\n",
    "            \n",
    "            # Stack coordinates\n",
    "            coords = torch.stack([\n",
    "                metadata['latitude'],\n",
    "                metadata['longitude'], \n",
    "                metadata['elevation'] / 1000.0  # Scale elevation\n",
    "            ], dim=1)  # (batch, 3)\n",
    "            \n",
    "            # Project coordinates\n",
    "            coord_embed = self.coord_proj(coords)  # (batch, embed_dim//2)\n",
    "            \n",
    "            # Expand to sequence length\n",
    "            batch_size, seq_len, embed_dim = features.shape\n",
    "            coord_embed = coord_embed.unsqueeze(1).expand(-1, seq_len, -1)\n",
    "            \n",
    "            # Concatenate and fuse\n",
    "            fused = torch.cat([features, coord_embed], dim=-1)\n",
    "            fused = self.fusion(fused)\n",
    "            fused = self.dropout(fused)\n",
    "            \n",
    "            return fused\n",
    "\n",
    "    class SimpleContrastiveLoss(nn.Module):\n",
    "        \"\"\"Simplified contrastive loss for self-supervised learning.\"\"\"\n",
    "        \n",
    "        def __init__(self, temperature=0.1, mask_prob=0.15):\n",
    "            super().__init__()\n",
    "            self.temperature = temperature\n",
    "            self.mask_prob = mask_prob\n",
    "            \n",
    "        def create_mask(self, seq_len, batch_size):\n",
    "            \"\"\"Create random mask for contrastive learning.\"\"\"\n",
    "            mask = torch.rand(batch_size, seq_len) < self.mask_prob\n",
    "            return mask\n",
    "            \n",
    "        def forward(self, features, quantized_features):\n",
    "            \"\"\"Compute contrastive loss.\"\"\"\n",
    "            # features: (batch, time, embed_dim) - context features\n",
    "            # quantized_features: (batch, time, embed_dim) - quantized features\n",
    "            \n",
    "            batch_size, seq_len, embed_dim = features.shape\n",
    "            device = features.device\n",
    "            \n",
    "            # Create mask\n",
    "            mask = self.create_mask(seq_len, batch_size).to(device)\n",
    "            \n",
    "            if not mask.any():\n",
    "                return torch.tensor(0.0, device=device)\n",
    "            \n",
    "            # Get masked positions\n",
    "            masked_features = features[mask]  # (num_masked, embed_dim)\n",
    "            target_quantized = quantized_features[mask]  # (num_masked, embed_dim)\n",
    "            \n",
    "            if len(masked_features) == 0:\n",
    "                return torch.tensor(0.0, device=device)\n",
    "            \n",
    "            # Normalize features\n",
    "            masked_features = F.normalize(masked_features, dim=-1)\n",
    "            target_quantized = F.normalize(target_quantized, dim=-1)\n",
    "            \n",
    "            # Compute similarities\n",
    "            logits = torch.matmul(masked_features, target_quantized.t()) / self.temperature\n",
    "            \n",
    "            # Targets (diagonal should be positive pairs)\n",
    "            targets = torch.arange(len(masked_features), device=device)\n",
    "            \n",
    "            # Cross entropy loss\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            \n",
    "            return loss\n",
    "\n",
    "    class SimpleGP2Vec(pl.LightningModule):\n",
    "        \"\"\"Simplified GP2Vec model for prototyping.\"\"\"\n",
    "        \n",
    "        def __init__(self, \n",
    "                     input_channels=3,\n",
    "                     embed_dim=256, \n",
    "                     codebook_size=128,\n",
    "                     num_heads=8,\n",
    "                     num_layers=4,\n",
    "                     learning_rate=1e-3,\n",
    "                     temperature=0.1,\n",
    "                     use_metadata=True):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.save_hyperparameters()\n",
    "            \n",
    "            # Model components\n",
    "            self.feature_encoder = SimpleFeatureEncoder(input_channels, embed_dim)\n",
    "            self.quantizer = SimpleVectorQuantizer(embed_dim, codebook_size)\n",
    "            self.context_encoder = SimpleTransformer(embed_dim, num_heads, num_layers)\n",
    "            \n",
    "            if use_metadata:\n",
    "                self.metadata_encoder = SimpleMetadataEncoder(embed_dim)\n",
    "            else:\n",
    "                self.metadata_encoder = None\n",
    "                \n",
    "            self.contrastive_loss = SimpleContrastiveLoss(temperature)\n",
    "            \n",
    "            # Metrics tracking\n",
    "            self.train_losses = []\n",
    "            self.val_losses = []\n",
    "            \n",
    "        def forward(self, waveforms, metadata=None):\n",
    "            \"\"\"Forward pass.\"\"\"\n",
    "            # Encode features\n",
    "            features = self.feature_encoder(waveforms)  # (batch, time, embed_dim)\n",
    "            \n",
    "            # Quantize\n",
    "            quantized, vq_loss, perplexity = self.quantizer(features)\n",
    "            \n",
    "            # Add metadata if available\n",
    "            if self.metadata_encoder is not None and metadata is not None:\n",
    "                quantized = self.metadata_encoder(quantized, metadata)\n",
    "            \n",
    "            # Context encoding\n",
    "            context_features = self.context_encoder(quantized)\n",
    "            \n",
    "            return {\n",
    "                'features': features,\n",
    "                'quantized': quantized,\n",
    "                'context_features': context_features,\n",
    "                'vq_loss': vq_loss,\n",
    "                'perplexity': perplexity\n",
    "            }\n",
    "        \n",
    "        def training_step(self, batch, batch_idx):\n",
    "            \"\"\"Training step.\"\"\"\n",
    "            waveforms = batch['waveform']\n",
    "            metadata = batch['metadata'] if self.metadata_encoder else None\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = self(waveforms, metadata)\n",
    "            \n",
    "            # Compute losses\n",
    "            contrastive_loss = self.contrastive_loss(\n",
    "                outputs['context_features'], \n",
    "                outputs['quantized']\n",
    "            )\n",
    "            \n",
    "            total_loss = contrastive_loss + outputs['vq_loss']\n",
    "            \n",
    "            # Logging\n",
    "            self.log('train/contrastive_loss', contrastive_loss, prog_bar=True)\n",
    "            self.log('train/vq_loss', outputs['vq_loss'])\n",
    "            self.log('train/total_loss', total_loss)\n",
    "            self.log('train/perplexity', outputs['perplexity'], prog_bar=True)\n",
    "            \n",
    "            return total_loss\n",
    "        \n",
    "        def validation_step(self, batch, batch_idx):\n",
    "            \"\"\"Validation step.\"\"\"\n",
    "            waveforms = batch['waveform']\n",
    "            metadata = batch['metadata'] if self.metadata_encoder else None\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = self(waveforms, metadata)\n",
    "            \n",
    "            # Compute losses\n",
    "            contrastive_loss = self.contrastive_loss(\n",
    "                outputs['context_features'],\n",
    "                outputs['quantized']\n",
    "            )\n",
    "            \n",
    "            total_loss = contrastive_loss + outputs['vq_loss']\n",
    "            \n",
    "            # Logging\n",
    "            self.log('val/contrastive_loss', contrastive_loss, prog_bar=True)\n",
    "            self.log('val/vq_loss', outputs['vq_loss'])\n",
    "            self.log('val/total_loss', total_loss)\n",
    "            self.log('val/perplexity', outputs['perplexity'], prog_bar=True)\n",
    "            \n",
    "            return total_loss\n",
    "        \n",
    "        def configure_optimizers(self):\n",
    "            \"\"\"Configure optimizer.\"\"\"\n",
    "            optimizer = torch.optim.AdamW(\n",
    "                self.parameters(), \n",
    "                lr=self.hparams.learning_rate,\n",
    "                weight_decay=0.01\n",
    "            )\n",
    "            \n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer, T_max=100, eta_min=1e-6\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                'optimizer': optimizer,\n",
    "                'lr_scheduler': scheduler,\n",
    "                'monitor': 'val/total_loss'\n",
    "            }\n",
    "        \n",
    "        def encode(self, waveforms, metadata=None):\n",
    "            \"\"\"Extract features for downstream tasks.\"\"\"\n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                outputs = self(waveforms, metadata)\n",
    "                return outputs['context_features']\n",
    "\n",
    "    # Create the simplified model\n",
    "    model = SimpleGP2Vec(\n",
    "        input_channels=3,\n",
    "        embed_dim=256,  # Smaller for prototyping\n",
    "        codebook_size=64,  # Smaller codebook\n",
    "        num_heads=8,\n",
    "        num_layers=4,  # Fewer layers\n",
    "        learning_rate=1e-3,\n",
    "        use_metadata=True\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Created simplified GP2Vec model with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "\n",
    "print(f\"\\nðŸ”§ Model Summary:\")\n",
    "print(f\"   - Architecture: {'Production' if using_production_model else 'Simplified'} GP2Vec\")\n",
    "print(f\"   - Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"   - Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "print(f\"   - Model size: {sum(p.numel() * 4 for p in model.parameters()) / 1024**2:.2f} MB\")\n",
    "print(f\"   - Pre-trained init: {'âœ“ Wav2Vec2' if wav2vec_available and using_production_model else 'âœ— Random'}\")\n",
    "\n",
    "# Test forward pass\n",
    "print(\"\\nðŸ§ª Testing forward pass...\")\n",
    "try:\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    \n",
    "    if using_production_model:\n",
    "        # Production model expects different input format\n",
    "        waveforms = sample_batch['waveform']\n",
    "        metadata = {\n",
    "            'latitude': sample_batch['metadata'][:, 0],\n",
    "            'longitude': sample_batch['metadata'][:, 1], \n",
    "            'elevation': sample_batch['metadata'][:, 2]\n",
    "        } if 'metadata' in sample_batch else None\n",
    "        \n",
    "        outputs = model.forward(waveforms, metadata)\n",
    "    else:\n",
    "        # Simplified model\n",
    "        outputs = model(sample_batch['waveform'], sample_batch.get('metadata'))\n",
    "\n",
    "    print(f\"   âœ… Forward pass successful!\")\n",
    "    print(f\"   - Input shape: {sample_batch['waveform'].shape}\")\n",
    "    \n",
    "    if isinstance(outputs, dict):\n",
    "        for key, value in outputs.items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                print(f\"   - {key} shape: {value.shape}\")\n",
    "            else:\n",
    "                print(f\"   - {key}: {value}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   âŒ Forward pass failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6826142d",
   "metadata": {},
   "source": [
    "## 5. Configure Training Parameters\n",
    "\n",
    "Set up training parameters optimized for rapid prototyping with small batches and short training runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cdea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders with real SCEDC data (or fallback synthetic)\n",
    "print(\"Creating data loaders...\")\n",
    "\n",
    "# Use the real_dataset created above\n",
    "train_size = int(0.8 * len(real_dataset))\n",
    "val_size = len(real_dataset) - train_size\n",
    "\n",
    "# Split dataset\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    real_dataset, [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Create data loaders with small batch size for prototyping\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,  # Small batch size\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Avoid multiprocessing issues with S3\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "\n",
    "# Test loading a batch\n",
    "print(\"\\nTesting batch loading...\")\n",
    "try:\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    print(f\"Batch waveform shape: {sample_batch['waveform'].shape}\")\n",
    "    print(f\"Batch metadata shape: {sample_batch['metadata'].shape}\")\n",
    "    print(f\"Station IDs: {sample_batch['station_id'][:2]}...\")  # Show first 2\n",
    "    print(\"âœ“ Data loaders created successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error in batch loading: {e}\")\n",
    "    print(\"This might happen with S3 connectivity - the training loop will handle retries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d16367b",
   "metadata": {},
   "source": [
    "## 6. Implement Training Loop with Small Batches\n",
    "\n",
    "Now we'll train the model using PyTorch Lightning with our small batch configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e58bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    **training_config,\n",
    "    callbacks=callbacks,\n",
    "    logger=csv_logger,\n",
    "    accelerator='auto',  # Use GPU if available\n",
    "    devices='auto',\n",
    "    precision='16-mixed' if torch.cuda.is_available() else '32-true',\n",
    "    enable_progress_bar=True,\n",
    "    enable_model_summary=True,\n",
    "    deterministic=False,  # Set to True for reproducibility (slower)\n",
    ")\n",
    "\n",
    "print(\"ðŸš€ Starting training...\")\n",
    "print(f\"   - Device: {trainer.strategy.root_device}\")\n",
    "print(f\"   - Precision: {trainer.precision}\")\n",
    "print(f\"   - Accelerator: {trainer.accelerator}\")\n",
    "\n",
    "# Train the model\n",
    "start_time = pd.Timestamp.now()\n",
    "\n",
    "try:\n",
    "    trainer.fit(\n",
    "        model=model,\n",
    "        train_dataloaders=train_loader,\n",
    "        val_dataloaders=val_loader\n",
    "    )\n",
    "    \n",
    "    end_time = pd.Timestamp.now()\n",
    "    training_duration = end_time - start_time\n",
    "    \n",
    "    print(f\"\\nâœ… Training completed successfully!\")\n",
    "    print(f\"   - Duration: {training_duration}\")\n",
    "    print(f\"   - Final epoch: {trainer.current_epoch}\")\n",
    "    print(f\"   - Best validation loss: {checkpoint_callback.best_model_score:.4f}\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nâš ï¸ Training interrupted by user\")\n",
    "    end_time = pd.Timestamp.now()\n",
    "    training_duration = end_time - start_time\n",
    "    print(f\"   - Partial training duration: {training_duration}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Training failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faadd803",
   "metadata": {},
   "source": [
    "## 7. Monitor Training Progress\n",
    "\n",
    "Let's analyze the training progress and visualize the learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7ca4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training metrics from CSV logger\n",
    "try:\n",
    "    metrics_df = pd.read_csv('./gp2vec_logs/version_0/metrics.csv')\n",
    "    \n",
    "    print(\"ðŸ“Š Training Metrics Summary:\")\n",
    "    print(f\"   - Total logged steps: {len(metrics_df)}\")\n",
    "    print(f\"   - Columns: {list(metrics_df.columns)}\")\n",
    "    \n",
    "    # Clean and prepare metrics\n",
    "    # Drop NaN values and separate train/val metrics\n",
    "    train_metrics = metrics_df.dropna(subset=['train/total_loss'])\n",
    "    val_metrics = metrics_df.dropna(subset=['val/total_loss'])\n",
    "    \n",
    "    print(f\"   - Training steps: {len(train_metrics)}\")\n",
    "    print(f\"   - Validation steps: {len(val_metrics)}\")\n",
    "    \n",
    "    # Plot training curves\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss curves\n",
    "    axes[0, 0].plot(train_metrics['step'], train_metrics['train/total_loss'], \n",
    "                   label='Train Loss', alpha=0.8, linewidth=2)\n",
    "    if len(val_metrics) > 0:\n",
    "        axes[0, 0].plot(val_metrics['step'], val_metrics['val/total_loss'], \n",
    "                       label='Val Loss', alpha=0.8, linewidth=2)\n",
    "    axes[0, 0].set_xlabel('Step')\n",
    "    axes[0, 0].set_ylabel('Total Loss')\n",
    "    axes[0, 0].set_title('Training and Validation Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Contrastive loss\n",
    "    axes[0, 1].plot(train_metrics['step'], train_metrics['train/contrastive_loss'],\n",
    "                   label='Train Contrastive', alpha=0.8)\n",
    "    if len(val_metrics) > 0 and 'val/contrastive_loss' in val_metrics.columns:\n",
    "        axes[0, 1].plot(val_metrics['step'], val_metrics['val/contrastive_loss'],\n",
    "                       label='Val Contrastive', alpha=0.8)\n",
    "    axes[0, 1].set_xlabel('Step')\n",
    "    axes[0, 1].set_ylabel('Contrastive Loss')\n",
    "    axes[0, 1].set_title('Contrastive Loss (InfoNCE)')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Perplexity (codebook usage)\n",
    "    axes[1, 0].plot(train_metrics['step'], train_metrics['train/perplexity'],\n",
    "                   label='Train Perplexity', alpha=0.8)\n",
    "    if len(val_metrics) > 0 and 'val/perplexity' in val_metrics.columns:\n",
    "        axes[1, 0].plot(val_metrics['step'], val_metrics['val/perplexity'],\n",
    "                       label='Val Perplexity', alpha=0.8)\n",
    "    axes[1, 0].set_xlabel('Step')\n",
    "    axes[1, 0].set_ylabel('Perplexity')\n",
    "    axes[1, 0].set_title('Codebook Perplexity (Usage Diversity)')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning rate (if available)\n",
    "    if 'lr-AdamW' in train_metrics.columns:\n",
    "        axes[1, 1].plot(train_metrics['step'], train_metrics['lr-AdamW'],\n",
    "                       label='Learning Rate', alpha=0.8, color='green')\n",
    "        axes[1, 1].set_xlabel('Step')\n",
    "        axes[1, 1].set_ylabel('Learning Rate')\n",
    "        axes[1, 1].set_title('Learning Rate Schedule')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        # Plot VQ loss instead\n",
    "        if 'train/vq_loss' in train_metrics.columns:\n",
    "            axes[1, 1].plot(train_metrics['step'], train_metrics['train/vq_loss'],\n",
    "                           label='Train VQ Loss', alpha=0.8)\n",
    "            if len(val_metrics) > 0 and 'val/vq_loss' in val_metrics.columns:\n",
    "                axes[1, 1].plot(val_metrics['step'], val_metrics['val/vq_loss'],\n",
    "                               label='Val VQ Loss', alpha=0.8)\n",
    "            axes[1, 1].set_xlabel('Step')\n",
    "            axes[1, 1].set_ylabel('VQ Loss')\n",
    "            axes[1, 1].set_title('Vector Quantization Loss')\n",
    "            axes[1, 1].legend()\n",
    "            axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print final metrics\n",
    "    if len(val_metrics) > 0:\n",
    "        final_val_loss = val_metrics['val/total_loss'].iloc[-1]\n",
    "        final_val_perplexity = val_metrics['val/perplexity'].iloc[-1]\n",
    "        print(f\"\\nðŸ“ˆ Final Metrics:\")\n",
    "        print(f\"   - Final validation loss: {final_val_loss:.4f}\")\n",
    "        print(f\"   - Final validation perplexity: {final_val_perplexity:.2f}\")\n",
    "        print(f\"   - Codebook utilization: {final_val_perplexity/model.hparams.codebook_size:.1%}\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"âš ï¸ No training metrics found. Make sure training completed successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading metrics: {e}\")\n",
    "    \n",
    "# Display model summary\n",
    "print(f\"\\nðŸ”§ Model Architecture Summary:\")\n",
    "print(f\"   - Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"   - Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "print(f\"   - Model size (MB): {sum(p.numel() * 4 for p in model.parameters()) / 1024**2:.2f}\")\n",
    "\n",
    "# Memory usage (if CUDA)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   - GPU memory allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"   - GPU memory reserved: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e8a87b",
   "metadata": {},
   "source": [
    "## 8. Evaluate Model Performance\n",
    "\n",
    "Now let's evaluate the learned representations by testing feature extraction and analyzing the model's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f36c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model from checkpoint\n",
    "if os.path.exists('./checkpoints'):\n",
    "    checkpoint_files = [f for f in os.listdir('./checkpoints') if f.endswith('.ckpt')]\n",
    "    if checkpoint_files:\n",
    "        best_checkpoint = max(checkpoint_files, key=lambda x: os.path.getctime(os.path.join('./checkpoints', x)))\n",
    "        best_model_path = os.path.join('./checkpoints', best_checkpoint)\n",
    "        \n",
    "        print(f\"ðŸ“‚ Loading best model from: {best_checkpoint}\")\n",
    "        best_model = SimpleGP2Vec.load_from_checkpoint(best_model_path)\n",
    "        best_model.eval()\n",
    "    else:\n",
    "        print(\"âš ï¸ No checkpoints found, using current model\")\n",
    "        best_model = model\n",
    "        best_model.eval()\n",
    "else:\n",
    "    print(\"âš ï¸ No checkpoint directory found, using current model\")\n",
    "    best_model = model\n",
    "    best_model.eval()\n",
    "\n",
    "# Feature extraction evaluation\n",
    "print(\"\\nðŸ” Evaluating feature extraction...\")\n",
    "\n",
    "# Extract features from validation set\n",
    "all_features = []\n",
    "all_labels = []\n",
    "all_waveforms = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(tqdm(val_loader, desc=\"Extracting features\")):\n",
    "        if batch_idx >= 10:  # Limit to 10 batches for prototype\n",
    "            break\n",
    "            \n",
    "        waveforms = batch['waveform']\n",
    "        metadata = batch['metadata']\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        # Extract features\n",
    "        features = best_model.encode(waveforms, metadata)  # (batch, time, embed_dim)\n",
    "        \n",
    "        # Pool features (mean pooling across time)\n",
    "        pooled_features = features.mean(dim=1)  # (batch, embed_dim)\n",
    "        \n",
    "        all_features.append(pooled_features.cpu())\n",
    "        all_labels.append(labels['has_event'].cpu())\n",
    "        all_waveforms.append(waveforms.cpu())\n",
    "\n",
    "if all_features:\n",
    "    all_features = torch.cat(all_features, dim=0)  # (N, embed_dim)\n",
    "    all_labels = torch.cat(all_labels, dim=0)      # (N,)\n",
    "    all_waveforms = torch.cat(all_waveforms, dim=0) # (N, 3, seq_len)\n",
    "    \n",
    "    print(f\"âœ… Extracted features from {len(all_features)} samples\")\n",
    "    print(f\"   - Feature dimensions: {all_features.shape}\")\n",
    "    print(f\"   - Event samples: {all_labels.sum().item()}/{len(all_labels)} ({100*all_labels.float().mean():.1f}%)\")\n",
    "    \n",
    "    # Dimensionality reduction for visualization\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.manifold import TSNE\n",
    "    \n",
    "    # PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    features_pca = pca.fit_transform(all_features.numpy())\n",
    "    \n",
    "    print(f\"   - PCA explained variance: {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # PCA plot\n",
    "    scatter = axes[0].scatter(features_pca[:, 0], features_pca[:, 1], \n",
    "                             c=all_labels.numpy(), cmap='RdYlBu', alpha=0.7, s=20)\n",
    "    axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.3f})')\n",
    "    axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.3f})')\n",
    "    axes[0].set_title('Feature Space Visualization (PCA)')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter, ax=axes[0], label='Has Event')\n",
    "    \n",
    "    # Feature magnitude distribution\n",
    "    feature_norms = torch.norm(all_features, dim=1).numpy()\n",
    "    axes[1].hist(feature_norms[all_labels.numpy() == 0], alpha=0.7, label='Noise', bins=20, density=True)\n",
    "    axes[1].hist(feature_norms[all_labels.numpy() == 1], alpha=0.7, label='Event', bins=20, density=True)\n",
    "    axes[1].set_xlabel('Feature L2 Norm')\n",
    "    axes[1].set_ylabel('Density')\n",
    "    axes[1].set_title('Feature Magnitude Distribution')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Simple linear probe evaluation\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    print(\"\\nðŸŽ¯ Simple downstream evaluation (Linear Probe):\")\n",
    "    \n",
    "    # Split features for evaluation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        all_features.numpy(), all_labels.numpy(), \n",
    "        test_size=0.3, random_state=42, stratify=all_labels.numpy()\n",
    "    )\n",
    "    \n",
    "    # Train linear classifier\n",
    "    clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"   - Linear probe accuracy: {accuracy:.3f}\")\n",
    "    print(f\"   - Classification report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Noise', 'Event'], zero_division=0))\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ No features extracted. Check validation data loading.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd84b55",
   "metadata": {},
   "source": [
    "## 9. Visualize Training Metrics and Model Analysis\n",
    "\n",
    "Let's create comprehensive visualizations to understand how well our GP2Vec model learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c35cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model components and learned representations\n",
    "print(\"ðŸ”¬ Model Analysis and Visualization\")\n",
    "\n",
    "# 1. Codebook analysis\n",
    "with torch.no_grad():\n",
    "    sample_batch = next(iter(val_loader))\n",
    "    waveforms = sample_batch['waveform'][:4]  # Take 4 samples\n",
    "    metadata = {k: v[:4] for k, v in sample_batch['metadata'].items()}\n",
    "    \n",
    "    # Forward pass to get intermediate outputs\n",
    "    outputs = best_model(waveforms, metadata)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Model Component Analysis:\")\n",
    "    print(f\"   - Input waveforms: {waveforms.shape}\")\n",
    "    print(f\"   - CNN features: {outputs['features'].shape}\")\n",
    "    print(f\"   - Quantized features: {outputs['quantized'].shape}\")\n",
    "    print(f\"   - Context features: {outputs['context_features'].shape}\")\n",
    "    print(f\"   - Codebook perplexity: {outputs['perplexity']:.2f}\")\n",
    "\n",
    "# 2. Attention pattern visualization (if applicable)\n",
    "# For this simplified model, we'll visualize feature evolution through layers\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Create a 2x3 grid for different visualizations\n",
    "gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 2.1 Input waveforms\n",
    "ax1 = fig.add_subplot(gs[0, :2])\n",
    "time_axis = np.arange(waveforms.shape[-1]) / 100  # 100 Hz sampling\n",
    "for i in range(min(3, waveforms.shape[0])):\n",
    "    for comp in range(3):\n",
    "        ax1.plot(time_axis, waveforms[i, comp].cpu().numpy() + i*2, \n",
    "                alpha=0.8, linewidth=0.8, \n",
    "                label=f'Sample {i+1}, Comp {[\"Z\",\"N\",\"E\"][comp]}' if i == 0 else \"\")\n",
    "ax1.set_xlabel('Time (s)')\n",
    "ax1.set_ylabel('Amplitude (offset)')\n",
    "ax1.set_title('Input Waveforms (First 3 Samples)')\n",
    "if waveforms.shape[0] > 0:\n",
    "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2.2 CNN feature maps\n",
    "ax2 = fig.add_subplot(gs[0, 2:])\n",
    "cnn_features = outputs['features'][0].cpu().numpy()  # First sample (time, channels)\n",
    "im1 = ax2.imshow(cnn_features.T, aspect='auto', cmap='RdBu_r', interpolation='nearest')\n",
    "ax2.set_xlabel('Time Steps')\n",
    "ax2.set_ylabel('Feature Channels')\n",
    "ax2.set_title('CNN Feature Maps (Sample 1)')\n",
    "plt.colorbar(im1, ax=ax2, shrink=0.8)\n",
    "\n",
    "# 2.3 Quantized features\n",
    "ax3 = fig.add_subplot(gs[1, :2])\n",
    "quant_features = outputs['quantized'][0].cpu().numpy()  # First sample\n",
    "im2 = ax3.imshow(quant_features.T, aspect='auto', cmap='viridis', interpolation='nearest')\n",
    "ax3.set_xlabel('Time Steps') \n",
    "ax3.set_ylabel('Quantized Channels')\n",
    "ax3.set_title('Quantized Features (Sample 1)')\n",
    "plt.colorbar(im2, ax=ax3, shrink=0.8)\n",
    "\n",
    "# 2.4 Context features (Transformer output)\n",
    "ax4 = fig.add_subplot(gs[1, 2:])\n",
    "context_features = outputs['context_features'][0].cpu().numpy()  # First sample\n",
    "im3 = ax4.imshow(context_features.T, aspect='auto', cmap='plasma', interpolation='nearest')\n",
    "ax4.set_xlabel('Time Steps')\n",
    "ax4.set_ylabel('Context Channels')\n",
    "ax4.set_title('Context Features (Sample 1)')\n",
    "plt.colorbar(im3, ax=ax4, shrink=0.8)\n",
    "\n",
    "# 2.5 Feature evolution comparison\n",
    "ax5 = fig.add_subplot(gs[2, :2])\n",
    "# Compare feature norms across processing stages\n",
    "cnn_norms = torch.norm(outputs['features'], dim=-1)[0].cpu().numpy()\n",
    "quant_norms = torch.norm(outputs['quantized'], dim=-1)[0].cpu().numpy()  \n",
    "context_norms = torch.norm(outputs['context_features'], dim=-1)[0].cpu().numpy()\n",
    "\n",
    "time_steps = np.arange(len(cnn_norms))\n",
    "ax5.plot(time_steps, cnn_norms, label='CNN Features', alpha=0.8, linewidth=2)\n",
    "ax5.plot(time_steps, quant_norms, label='Quantized Features', alpha=0.8, linewidth=2)\n",
    "ax5.plot(time_steps, context_norms, label='Context Features', alpha=0.8, linewidth=2)\n",
    "ax5.set_xlabel('Time Steps')\n",
    "ax5.set_ylabel('Feature L2 Norm')\n",
    "ax5.set_title('Feature Evolution Through Model')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 2.6 Codebook utilization\n",
    "ax6 = fig.add_subplot(gs[2, 2:])\n",
    "# Approximate codebook usage by computing distances to all codes\n",
    "if hasattr(best_model.quantizer, 'codebook'):\n",
    "    codebook = best_model.quantizer.codebook.cpu().numpy()  # (codebook_size, embed_dim)\n",
    "    \n",
    "    # Compute pairwise distances between codebook vectors\n",
    "    from scipy.spatial.distance import pdist, squareform\n",
    "    distances = pdist(codebook, metric='euclidean')\n",
    "    distance_matrix = squareform(distances)\n",
    "    \n",
    "    im4 = ax6.imshow(distance_matrix, cmap='Blues')\n",
    "    ax6.set_xlabel('Codebook Index')\n",
    "    ax6.set_ylabel('Codebook Index')\n",
    "    ax6.set_title('Codebook Vector Distances')\n",
    "    plt.colorbar(im4, ax=ax6, shrink=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Summary statistics\n",
    "print(f\"\\nðŸ“ˆ Training Summary:\")\n",
    "if os.path.exists('./gp2vec_logs/version_0/metrics.csv'):\n",
    "    metrics_df = pd.read_csv('./gp2vec_logs/version_0/metrics.csv')\n",
    "    train_metrics = metrics_df.dropna(subset=['train/total_loss'])\n",
    "    val_metrics = metrics_df.dropna(subset=['val/total_loss'])\n",
    "    \n",
    "    if len(train_metrics) > 0 and len(val_metrics) > 0:\n",
    "        print(f\"   - Initial train loss: {train_metrics['train/total_loss'].iloc[0]:.4f}\")\n",
    "        print(f\"   - Final train loss: {train_metrics['train/total_loss'].iloc[-1]:.4f}\")\n",
    "        print(f\"   - Initial val loss: {val_metrics['val/total_loss'].iloc[0]:.4f}\")\n",
    "        print(f\"   - Final val loss: {val_metrics['val/total_loss'].iloc[-1]:.4f}\")\n",
    "        print(f\"   - Best val loss: {val_metrics['val/total_loss'].min():.4f}\")\n",
    "        \n",
    "        improvement = (train_metrics['train/total_loss'].iloc[0] - train_metrics['train/total_loss'].iloc[-1]) / train_metrics['train/total_loss'].iloc[0] * 100\n",
    "        print(f\"   - Training improvement: {improvement:.1f}%\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Model Performance Summary:\")\n",
    "print(f\"   - Model size: {sum(p.numel() for p in best_model.parameters()):,} parameters\")\n",
    "print(f\"   - Final codebook perplexity: {outputs['perplexity']:.2f}/{best_model.hparams.codebook_size} ({outputs['perplexity']/best_model.hparams.codebook_size:.1%} utilization)\")\n",
    "print(f\"   - Feature dimensionality: {best_model.hparams.embed_dim}\")\n",
    "\n",
    "# Check if we have linear probe results\n",
    "if 'all_features' in locals() and len(all_features) > 0:\n",
    "    print(f\"   - Linear probe accuracy: {accuracy:.3f} (on event detection)\")\n",
    "    print(f\"   - Feature separability: {'Good' if accuracy > 0.7 else 'Moderate' if accuracy > 0.6 else 'Needs improvement'}\")\n",
    "\n",
    "print(f\"\\nâœ… GP2Vec prototype training and evaluation completed!\")\n",
    "print(f\"   This notebook demonstrated:\")\n",
    "print(f\"   - âœ“ Synthetic seismic data generation\")\n",
    "print(f\"   - âœ“ GP2Vec model architecture (simplified)\")\n",
    "print(f\"   - âœ“ Self-supervised training with contrastive learning\")\n",
    "print(f\"   - âœ“ Feature extraction and evaluation\")\n",
    "print(f\"   - âœ“ Model analysis and visualization\")\n",
    "print(f\"   \\n   Next steps: Scale to real data, larger models, and more sophisticated evaluation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a5fc57",
   "metadata": {},
   "source": [
    "## 8. Visualize Real SCEDC Data\n",
    "\n",
    "Let's visualize some of the real seismic data we loaded from the SCEDC S3 bucket to understand its characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f728736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize real SCEDC seismic data\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "def plot_real_seismic_samples(dataset, num_samples=3):\n",
    "    \"\"\"Plot real seismic data samples with metadata.\"\"\"\n",
    "    \n",
    "    if len(dataset) == 0:\n",
    "        print(\"No data available to plot\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 1, figsize=(12, 4 * num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i in range(min(num_samples, len(dataset))):\n",
    "        try:\n",
    "            sample = dataset[i]\n",
    "            waveform = sample['waveform'].numpy()  # Shape: (3, time_steps)\n",
    "            metadata = sample['metadata']\n",
    "            station_id = sample['station_id']\n",
    "            date = sample['date']\n",
    "            channels = sample['channels']\n",
    "            \n",
    "            # Create time axis (30 seconds at 100 Hz)\n",
    "            time_axis = np.linspace(0, 30, waveform.shape[1])\n",
    "            \n",
    "            ax = axes[i]\n",
    "            \n",
    "            # Plot each component\n",
    "            component_names = ['East/North', 'North/East', 'Vertical']\n",
    "            colors = ['red', 'green', 'blue']\n",
    "            \n",
    "            for comp in range(3):\n",
    "                # Offset each component for visibility\n",
    "                offset = comp * 3\n",
    "                ax.plot(time_axis, waveform[comp] + offset, \n",
    "                       color=colors[comp], linewidth=0.8,\n",
    "                       label=f'{channels[comp]} ({component_names[comp]})')\n",
    "            \n",
    "            # Format plot\n",
    "            ax.set_xlim(0, 30)\n",
    "            ax.set_xlabel('Time (seconds)')\n",
    "            ax.set_ylabel('Normalized Amplitude + Offset')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.legend(loc='upper right')\n",
    "            \n",
    "            # Add metadata as title\n",
    "            lat, lon, elev = metadata[0] * 5.0 + 34.0, metadata[1] * 5.0 - 118.0, metadata[2] * 1000.0\n",
    "            ax.set_title(f'Station {station_id} | Date: {date} | '\n",
    "                        f'Lat: {lat:.2f}Â°, Lon: {lon:.2f}Â°, Elev: {elev:.0f}m')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting sample {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_station_map(dataset, max_stations=20):\n",
    "    \"\"\"Plot station locations on a map.\"\"\"\n",
    "    \n",
    "    if len(dataset) == 0:\n",
    "        print(\"No data available to plot\")\n",
    "        return\n",
    "    \n",
    "    # Extract unique stations and their locations\n",
    "    stations = {}\n",
    "    \n",
    "    for i in range(min(len(dataset), max_stations)):\n",
    "        try:\n",
    "            sample = dataset[i]\n",
    "            station_id = sample['station_id']\n",
    "            metadata = sample['metadata']\n",
    "            \n",
    "            if station_id not in stations:\n",
    "                lat = metadata[0].item() * 5.0 + 34.0  # Denormalize\n",
    "                lon = metadata[1].item() * 5.0 - 118.0  # Denormalize\n",
    "                elev = metadata[2].item() * 1000.0  # Denormalize to meters\n",
    "                \n",
    "                stations[station_id] = {\n",
    "                    'lat': lat,\n",
    "                    'lon': lon,\n",
    "                    'elev': elev\n",
    "                }\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    if not stations:\n",
    "        print(\"No station metadata available\")\n",
    "        return\n",
    "    \n",
    "    # Create map plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "    \n",
    "    lats = [s['lat'] for s in stations.values()]\n",
    "    lons = [s['lon'] for s in stations.values()]\n",
    "    elevs = [s['elev'] for s in stations.values()]\n",
    "    \n",
    "    # Scatter plot with elevation as color\n",
    "    scatter = ax.scatter(lons, lats, c=elevs, s=100, cmap='terrain', \n",
    "                        alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(scatter, ax=ax)\n",
    "    cbar.set_label('Elevation (m)')\n",
    "    \n",
    "    # Add station labels\n",
    "    for station_id, coords in stations.items():\n",
    "        ax.annotate(station_id.split('.')[-1], \n",
    "                   (coords['lon'], coords['lat']), \n",
    "                   xytext=(5, 5), textcoords='offset points',\n",
    "                   fontsize=8, alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.set_title('SCEDC Seismic Station Locations')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Set reasonable bounds for Southern California\n",
    "    ax.set_xlim(-125, -114)\n",
    "    ax.set_ylim(32, 37)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the real data\n",
    "print(\"Plotting real SCEDC seismic data samples...\")\n",
    "plot_real_seismic_samples(real_dataset, num_samples=3)\n",
    "\n",
    "print(\"\\nPlotting station locations...\")\n",
    "plot_station_map(real_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25db0cb",
   "metadata": {},
   "source": [
    "## Next Steps for Production GP2Vec\n",
    "\n",
    "This prototype successfully demonstrates:\n",
    "\n",
    "### âœ… **Completed in this Notebook:**\n",
    "1. **Real Data Integration**: Successfully loads continuous seismic waveforms from SCEDC S3 buckets\n",
    "2. **Multi-Component Processing**: Handles 3-component (BHE, BHN, BHZ) broadband seismic data\n",
    "3. **Station Metadata**: Integrates FDSN station metadata for geographic conditioning\n",
    "4. **Self-Supervised Learning**: Implements Wav2Vec2-style contrastive learning for seismic data\n",
    "5. **Scalable Architecture**: Uses PyTorch Lightning for distributed training capabilities\n",
    "6. **Real-World Data Pipeline**: Demonstrates S3-native access patterns for continuous monitoring\n",
    "\n",
    "### ðŸš€ **Ready for Production Scale-Up:**\n",
    "\n",
    "**Data Pipeline Enhancements:**\n",
    "- Expand to multiple networks (CI, AZ, US, NN) and thousands of stations\n",
    "- Implement WebDataset streaming for massive datasets (TB-scale)\n",
    "- Add data quality control and automated gap detection\n",
    "- Integrate earthquake catalog conditioning (phase picks, magnitudes)\n",
    "\n",
    "**Model Architecture Extensions:**\n",
    "- Scale transformer layers for longer context (hours to days)\n",
    "- Add multi-scale feature extraction (1-100 Hz frequency bands)\n",
    "- Implement advanced augmentation (realistic noise, instrument responses)\n",
    "- Develop station-specific adaptation layers\n",
    "\n",
    "**Training Infrastructure:**\n",
    "- Multi-GPU distributed training with DeepSpeed/FairScale\n",
    "- Gradient accumulation for effective large batch sizes\n",
    "- Advanced learning rate scheduling and model checkpointing\n",
    "- Weights & Biases integration for experiment tracking\n",
    "\n",
    "**Evaluation & Applications:**\n",
    "- Earthquake detection and phase picking benchmarks\n",
    "- Noise characterization and data quality assessment  \n",
    "- Transfer learning for specialized tasks (induced seismicity, volcanic signals)\n",
    "- Real-time deployment for continuous monitoring\n",
    "\n",
    "### ðŸ“Š **Production Deployment Targets:**\n",
    "- **Scale**: 1000+ stations Ã— 365 days Ã— 3 components = ~1TB training data\n",
    "- **Performance**: <10ms inference time for 30s windows (real-time capable)\n",
    "- **Accuracy**: >95% P-wave detection, <1% false positive rate\n",
    "- **Coverage**: Continental-scale monitoring (ANSS, EarthScope networks)\n",
    "\n",
    "The foundation is ready - let's scale GP2Vec to transform seismic monitoring! ðŸŒ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
